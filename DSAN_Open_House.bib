@article{acharya2023slavery,
  title = {Slavery, {{Politics}}, and {{Causality}}},
  author = {Acharya, Avidit and Blackwell, Matthew and Sen, Maya},
  year = {2023},
  journal = {Harvard Kennedy School Working Paper},
  url = {https://www.hks.harvard.edu/publications/slavery-politics-and-causality}
}

@article{bind2019causal,
  title = {Causal {{Modeling}} in {{Environmental Health}}},
  author = {Bind, Marie-Ab{\`e}le},
  year = {2019},
  month = apr,
  journal = {Annual review of public health},
  volume = {40},
  pages = {23--43},
  issn = {0163-7525},
  doi = {10.1146/annurev-publhealth-040218-044048},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6445691/},
  urldate = {2025-02-28},
  abstract = {The field of environmental health has been dominated by modeling associations, especially by regressing an observed outcome on a linear or nonlinear function of observed covariates. Readers interested in advances in policies for improving environmental health are, however, expecting to be informed about health effects resulting from, or more explicitly caused by, environmental exposures. The quantification of health impacts resulting from the removal of environmental exposures involves causal statements. Therefore, when possible, causal inference frameworks should be considered for analyzing the effects of environmental exposures on health outcomes.},
  pmcid = {PMC6445691},
  pmid = {30633715},
  file = {/Users/jpj/Zotero/storage/YPYLPANB/Bind - 2019 - Causal Modeling in Environmental Health.pdf}
}

@misc{bjorkegren2022machine,
  title = {({{Machine}}) {{Learning What Policies Value}}},
  author = {Bj{\"o}rkegren, Daniel and Blumenstock, Joshua E. and Knight, Samsun},
  year = {2022},
  month = jun,
  number = {arXiv:2206.00727},
  eprint = {2206.00727},
  primaryclass = {cs, econ, q-fin},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2206.00727},
  url = {http://arxiv.org/abs/2206.00727},
  urldate = {2024-01-17},
  abstract = {When a policy prioritizes one person over another, is it because they benefit more, or because they are preferred? This paper develops a method to uncover the values consistent with observed allocation decisions. We use machine learning methods to estimate how much each individual benefits from an intervention, and then reconcile its allocation with (i) the welfare weights assigned to different people; (ii) heterogeneous treatment effects of the intervention; and (iii) weights on different outcomes. We demonstrate this approach by analyzing Mexico's PROGRESA anti-poverty program. The analysis reveals that while the program prioritized certain subgroups -- such as indigenous households -- the fact that those groups benefited more implies that they were in fact assigned a lower welfare weight. The PROGRESA case illustrates how the method makes it possible to audit existing policies, and to design future policies that better align with values.},
  archiveprefix = {arXiv},
  file = {/Users/jpj/Zotero/storage/AN664DHZ/Björkegren et al. - 2022 - (Machine) Learning What Policies Value.pdf;/Users/jpj/Zotero/storage/5YYKJE54/2206.html}
}

@book{dignazio_data_2020,
  title = {Data {{Feminism}}},
  author = {D'Ignazio, Catherine and Klein, Lauren F.},
  year = {2020},
  month = mar,
  publisher = {MIT Press},
  abstract = {A new way of thinking about data science and data ethics that is informed by the ideas of intersectional feminism.Today, data science is a form of power. It has been used to expose injustice, improve health outcomes, and topple governments. But it has also been used to discriminate, police, and surveil. This potential for good, on the one hand, and harm, on the other, makes it essential to ask: Data science by whom? Data science for whom? Data science with whose interests in mind? The narratives around big data and data science are overwhelmingly white, male, and techno-heroic. In Data Feminism, Catherine D'Ignazio and Lauren Klein present a new way of thinking about data science and data ethics---one that is informed by intersectional feminist thought.Illustrating data feminism in action, D'Ignazio and Klein show how challenges to the male/female binary can help challenge other hierarchical (and empirically wrong) classification systems. They explain how, for example, an understanding of emotion can expand our ideas about effective data visualization, and how the concept of invisible labor can expose the significant human efforts required by our automated systems. And they show why the data never, ever ``speak for themselves.''Data Feminism offers strategies for data scientists seeking to learn how feminism can help them work toward justice, and for feminists who want to focus their efforts on the growing field of data science. But Data Feminism is about much more than gender. It is about power, about who has it and who doesn't, and about how those differentials of power can be challenged and changed.},
  googlebooks = {zZnSDwAAQBAJ},
  isbn = {978-0-262-35853-8},
  langid = {english}
}

@book{hume1739treatise,
  title = {A {{Treatise}} of {{Human Nature}}: {{Being}} an {{Attempt}} to {{Introduce}} the {{Experimental Method}} of {{Reasoning Into Moral Subjects}}; and {{Dialogues Concerning Natural Religion}}},
  shorttitle = {A {{Treatise}} of {{Human Nature}}},
  author = {Hume, David},
  year = {1739},
  publisher = {Longmans, Green},
  langid = {english}
}

@article{ingold_amazon_2016,
  title = {Amazon {{Doesn}}'t {{Consider}} the {{Race}} of {{Its Customers}}. {{Should It}}?},
  author = {Ingold, David and Soper, Spencer},
  year = {2016},
  month = apr,
  journal = {Bloomberg},
  url = {http://www.bloomberg.com/graphics/2016-amazon-same-day/},
  urldate = {2024-01-31},
  abstract = {In six big cities, Amazon Prime Same-Day delivery doesn't serve black ZIP codes as well as it does white ones.},
  langid = {english},
  file = {/Users/jpj/Zotero/storage/6DMRE4S7/2016-amazon-same-day.html}
}

@techreport{schiebinger_machine_2020,
  title = {Machine {{Translation}}: {{Gendered Innovations}}},
  author = {Schiebinger, Londa and Klinga, Ineke and Paik, Hee Young and {S{\'a}nchez de Madariaga}, In{\'e}s and Schraudner, Martina and Stefanick, Marcia},
  year = {2020},
  url = {http://genderedinnovations.stanford.edu/case-studies/nlp.html#tabs-2},
  urldate = {2022-04-13},
  file = {/Users/jpj/Zotero/storage/PDZWL4Q5/nlp.html}
}

@article{wagner_privacy_2023,
  title = {Privacy {{Policies}} across the {{Ages}}: {{Content}} of {{Privacy Policies}} 1996--2021},
  shorttitle = {Privacy {{Policies}} across the {{Ages}}},
  author = {Wagner, Isabel},
  year = {2023},
  month = may,
  journal = {ACM Transactions on Privacy and Security},
  volume = {26},
  number = {3},
  pages = {32:1--32:32},
  issn = {2471-2566},
  doi = {10.1145/3590152},
  url = {https://dl.acm.org/doi/10.1145/3590152},
  urldate = {2024-03-04},
  abstract = {It is well known that most users do not read privacy policies but almost always tick the box to agree with them. While the length and readability of privacy policies have been well studied and many approaches for policy analysis based on natural language processing have been proposed, existing studies are limited in their depth and scope, often focusing on a small number of data practices at single point in time. In this article, we fill this gap by analyzing the 25-year history of privacy policies using machine learning and natural language processing and presenting a comprehensive analysis of policy contents. Specifically, we collect a large-scale longitudinal corpus of privacy policies from 1996 to 2021 and analyze their content in terms of the data practices they describe, the rights they grant to users, and the rights they reserve for their organizations. We pay particular attention to changes in response to recent privacy regulations such as the GDPR and CCPA. We observe some positive changes, such as reductions in data collection post-GDPR, but also a range of concerning data practices, such as widespread implicit data collection for which users have no meaningful choices or access rights. Our work is an important step toward making privacy policies machine readable on the user side, which would help users match their privacy preferences against the policies offered by web services.},
  file = {/Users/jpj/Zotero/storage/QGUTTKTY/Wagner - 2023 - Privacy Policies across the Ages Content of Privacy Policies 1996–2021.pdf}
}

@inproceedings{wan_kelly_2023,
  title = {``{{Kelly}} Is a {{Warm Person}}, {{Joseph}} Is a {{Role Model}}'': {{Gender Biases}} in {{LLM-Generated Reference Letters}}},
  shorttitle = {``{{Kelly}} Is a {{Warm Person}}, {{Joseph}} Is a {{Role Model}}''},
  booktitle = {{{EMNLP}} 2023},
  author = {Wan, Yixin and Pu, George and Sun, Jiao and Garimella, Aparna and Chang, Kai-Wei and Peng, Nanyun},
  year = {2023},
  month = dec,
  pages = {3730--3748},
  publisher = {ACL},
  address = {Singapore},
  doi = {10.18653/v1/2023.findings-emnlp.243},
  url = {https://aclanthology.org/2023.findings-emnlp.243},
  urldate = {2024-11-22},
  file = {/Users/jpj/Zotero/storage/55UV8HQD/Wan et al. - 2023 - “Kelly is a Warm Person, Joseph is a Role Model” .pdf}
}
